# -*- coding: utf-8 -*-
"""Assigment_zero.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yI77SMulpl4p_A9ORdPizXKoMxue0puh
"""



import streamlit as st
import numpy as np
import numpy.linalg as la
import pickle
from math import sqrt
from PIL import Image

"""
This is a starter code for Assignment 0 of the course, "Hands-on Master Class on LLMs and ChatGPT | Autumn 2023"
taught by Dr. Karthik Mohan.

Computes closest category of a given word or sentence input into a search bar.
The search is implemented through streamlit and can be hosted as a "web app" on the cloud through streamlit as well
Example webpage and search demo: searchdemo.streamlit.app
"""


# Compute Cosine Similarity
def cosine_similarity(array_1,array_2):
    sum = 0
    sumx1 = 0
    sumy1 = 0
    x_arr = np.array(array_1)
    y_arr = np.array(array_2)

    for i, j in zip(x_arr, y_arr):
      sumx1 += i*i
      sumy1 += j*j
      sum += i*j
    cosine_sim = sum / ((sqrt(sumx1)) * (sqrt(sumy1)))


    #cos = np.cos(x_arr, y_arr)

    return cosine_sim

def create_pickle_fom_txt(txt_file = "sample_data/glove.6B.50d.txt"):

  embedding_dict = {}
  with open(txt_file, "r") as f:
    for line in f:
      word = line.split(" ")[0]
      embedding = np.array([float(val) for val in line.split(" ")[1:]])
      embedding_dict[word] = embedding
  try:
    file = open("sample_data/embedding_dict.pkl", "wb")
    pickle.dump(embedding_dict, file)
    print("Successfully pickled data")

  except Exception as error:
    print(f"Failed to pickle data, ERROR: {error}")



# Function to Load Glove Embeddings
def load_glove_embeddings(glove_path="sample_data/embedding_dict.pkl"):
    """
    First step: Download the 50d Glove embeddings from here - thttps://www.kaggle.com/datasets/adityajn105/glove6b50d
    Second step: Format the glove embeddings into a dictionary that goes from a word to the 50d embedding.
    Third step: Store the 50d Glove embeddings in a pickle file of a dictionary.
    Now load that pickle file back in this function
    """

    try:
        with open(glove_path,"rb") as f:
            embeddings_dict = pickle.load(f)

        print("Successfully un-pickled data")
        return embeddings_dict
    except Exception as error:
        print("failed to load Glove Embeddings", error)


# Get Averaged Glove Embedding of a sentence
def averaged_glove_embeddings(sentence, embeddings_dict):
    """
    Simple sentence embedding: Embedding of a sentence is the average of the word embeddings
    """
    words = sentence.split(" ")
    glove_embedding = np.zeros(50)
    count_words = 0

    for word in words:
      glove_embedding += embeddings_dict[word]

    return glove_embedding / len(words)



# if __name__ == "__main__":
#     embeddings_dict = load_glove_embeddings()
#     #print(embeddings_dict['dog'])

#     embeddings1 = averaged_glove_embeddings(sentence = "me",embeddings_dict = embeddings_dict)
#     embeddings2 = averaged_glove_embeddings(sentence = "i", embeddings_dict = embeddings_dict)

#     embeddings3 = averaged_glove_embeddings(sentence = "me",embeddings_dict = embeddings_dict)
#     embeddings4 = averaged_glove_embeddings(sentence = "myself", embeddings_dict = embeddings_dict)

#     print(cosine_similarity(embeddings1 ,embeddings2))
#     print(cosine_similarity(embeddings3 ,embeddings4))

#     # print(embeddings_dict["flower"] + embeddings_dict["water"])
#     # print((embeddings_dict["flower"] + embeddings_dict["water"]) / 2)


#     flower_plant = cosine_similarity(embeddings_dict["flower"], embeddings_dict["plant"])
#     flower_dog = cosine_similarity(embeddings_dict["flower"], embeddings_dict["dog"])

if __name__ == "__main__":
    load_glove_embeddings()
# Load glove embeddings
glove_embeddings = load_glove_embeddings()

image_words = ["flower","vehicle","tree","mountain","building"]

# Load in images
# i know this might be the least efficient way to do this but it get's the job done :/
flower = Image.open(r'sample_data/Images/Flower.png')
vehicle = Image.open(r'sample_data/Images/Vehicle.png')
tree = Image.open(r'sample_data/Images/Tree.png')
mountain = Image.open(r'sample_data/Images/Mountain.png')
building = Image.open(r'sample_data/Images/Building.png')

# Text Search
st.title("Search Based Retrieval Demo")
st.subheader("Pass in an input word or even a sentence (e.g. jasmine or mount adams)")
text_search = st.text_input("", value="")


# Find closest word to an input word
if text_search:
    input_embedding = averaged_glove_embeddings(text_search, glove_embeddings)
    cosine_sim = {}
    for index in range(len(image_words)):
        cosine_sim[index] = cosine_similarity(input_embedding, glove_embeddings[image_words[index]])


    # Sort the cosine similarities

    sorted_cosine_sim = sorted(cosine_sim, key=cosine_sim.get, reverse=True)

    if image_words[sorted_cosine_sim[0]] == "flower":
      closest_image = flower
    if image_words[sorted_cosine_sim[0]] == "vehicle":
      closest_image = vehicle
    if image_words[sorted_cosine_sim[0]] == "tree":
      closest_image = tree
    if image_words[sorted_cosine_sim[0]] == "mountain":
      closest_image = mountain
    if image_words[sorted_cosine_sim[0]] == "building":
      closest_image = building
      
    

    st.write("(My search uses glove embeddings)")
    st.write(f"Closest word I have between flower, mountain, tree, car and building for your input is: {image_words[sorted_cosine_sim[0]]}")
    st.subheader(image_words[sorted_cosine_sim[0]])
    st.image(closest_image, "Closest matching image")
    st.write("")
